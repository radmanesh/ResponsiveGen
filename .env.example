# API Keys
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# LLM Configuration
DEFAULT_LLM_PROVIDER=openai  # Options: openai, anthropic
DEFAULT_MODEL=gpt-4o  # or claude-3-opus-20240229, gpt-4o-mini

# Generation Settings
MAX_TOKENS=4096
TEMPERATURE=0.3

# Rendering Configuration
PLAYWRIGHT_HEADLESS=true
SCREENSHOT_QUALITY=90

# Evaluation Settings
RESPONSIVE_METER_W1=0.35  # IoU weight
RESPONSIVE_METER_W2=0.25  # Cross-device consistency weight
RESPONSIVE_METER_W3=0.25  # LLM judge weight
RESPONSIVE_METER_W4=0.15  # Perceptual similarity weight

# Output Paths
OUTPUT_DIR=outputs
CACHE_DIR=.cache

# Logging
LOG_LEVEL=INFO

# Agent-Specific Model Configuration
# Generator Agent (ResponsiveGenerator)
GENERATOR_PROVIDER=openai
GENERATOR_MODEL=gpt-4o
GENERATOR_TEMPERATURE=0.3
GENERATOR_MAX_TOKENS=4096

# Orchestrator Agent (orchestrator, reviewer, editor nodes)
ORCHESTRATOR_PROVIDER=openai
ORCHESTRATOR_MODEL=gpt-4o
ORCHESTRATOR_TEMPERATURE=0.3

# Evaluator Agent (LLMJudge)
EVALUATOR_PROVIDER=openai
EVALUATOR_MODEL=gpt-4o
EVALUATOR_TEMPERATURE=0.1

# LLM Debug Logging Configuration
# Options: NONE, INFO, DEBUG, TRACE
# NONE: No logging (default, completely silent)
# INFO: Basic call info (component, model, latency, token count)
# DEBUG: Request/response summaries with truncated content previews (~200 chars)
# TRACE: Full detail including complete message content, tool definitions, all metadata
LLM_DEBUG_LEVEL=NONE

# File Logging Configuration
# Save logs to files (true/false)
LLM_LOG_TO_FILE=true

# Base directory for log files (relative to project root)
# Logs are saved to: {LLM_LOG_DIR}/{sample_id}/logs/llm_calls.jsonl
LLM_LOG_DIR=outputs
